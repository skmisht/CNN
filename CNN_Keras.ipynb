{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9Hou45WbE2Ck4xQWPhca6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skmisht/CNN/blob/main/CNN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8jUjF3qksDK"
      },
      "source": [
        "#Melanoma detection using - Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-9WZvYe2xWj"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Roi5VUkjat",
        "outputId": "9a7afeee-8342-4a6a-a84c-0ec298089191"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85VH2rGB2vZc"
      },
      "source": [
        "Data Preparation\r\n",
        "\r\n",
        "```\r\n",
        "1.   Training Data\r\n",
        "2.   Validation Data\r\n",
        "3.   Training Data\r\n",
        "\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaRD_vSWnHdT",
        "outputId": "5304f9a6-10e9-4594-f0f5-2211b3d782de"
      },
      "source": [
        "import pandas as pd \r\n",
        "\r\n",
        "training_truth_data = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Part3_GroundTruth.csv') \r\n",
        "testing_truth_data = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Test_v2_Part3_GroundTruth.csv') \r\n",
        "validation_truth_data = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Validation_Part3_GroundTruth.csv')\r\n",
        "\r\n",
        "training_metadata = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC-2017_Training_Data_metadata.csv')\r\n",
        "testing_metadata = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Test_v2_Data/ISIC-2017_Test_v2_Data/ISIC-2017_Test_v2_Data_metadata.csv')\r\n",
        "validation_metadata = pd.read_csv('/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Validation_Data/ISIC-2017_Validation_Data/ISIC-2017_Validation_Data_metadata.csv')\r\n",
        "\r\n",
        "path_training_images ='/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/'\r\n",
        "path_testing_images ='/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Test_v2_Data/ISIC-2017_Test_v2_Data/'\r\n",
        "path_validation_images = '/content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Validation_Data/ISIC-2017_Validation_Data/'\r\n",
        "\r\n",
        "\r\n",
        "#add new column to truth_data witht he path to corresponding image\r\n",
        "def prepare_data(truth_data, metadata, image_path):\r\n",
        "  path_to_images_array = []\r\n",
        "  for x in truth_data.values:\r\n",
        "    path_to_image = image_path+str(x[0])+'.jpg'\r\n",
        "    path_to_images_array.append(str(path_to_image))\r\n",
        "  #add path to image to the truth data frame\r\n",
        "  truth_data['path_to_image'] = path_to_images_array\r\n",
        "  #return merge truth data with metadata, join on the image_id's\r\n",
        "  return pd.merge(truth_data, metadata, left_on='image_id', right_on='image_id', how='left')\r\n",
        "\r\n",
        "\r\n",
        "training_data = prepare_data(training_truth_data, training_metadata, path_training_images)\r\n",
        "testing_data = prepare_data(testing_truth_data, testing_metadata, path_testing_images)\r\n",
        "validation_data = prepare_data(validation_truth_data, validation_metadata, path_validation_images)\r\n",
        "\r\n",
        "'''\r\n",
        "#add new column to training_truth_data witht he path to corresponding image\r\n",
        "path_to_training_images_array = []\r\n",
        "for x in training_truth_data.values:\r\n",
        "    path_to_image = path_training_images + str(x[0]) +'.jpg'\r\n",
        "    path_to_training_images_array.append(str(path_to_image))\r\n",
        "#add path to image to the training data frame\r\n",
        "training_truth_data['path_to_image'] = path_to_training_images_array\r\n",
        "#merge training truth data with metadata, join on the image_id's\r\n",
        "training_data = pd.merge(training_truth_data, training_metadata, left_on='image_id', right_on='image_id', how='left')\r\n",
        "\r\n",
        "#add new column to test_truth_data witht he path to corresponding image\r\n",
        "path_to_test_images_array = []\r\n",
        "for x in testing_truth_data.values:\r\n",
        "  path_to_image = path_testing_images + str(x[0])+'.jpg'\r\n",
        "  path_to_test_images_array.append(path_to_image)\r\n",
        "#add path to image to the testing data frame\r\n",
        "testing_truth_data['path_to_image'] = path_to_test_images_array\r\n",
        "#merge testing truth data with metadata, join on the image_id's\r\n",
        "testing_data = pd.merge(testing_truth_data, testing_metadata, left_on='image_id', right_on='image_id', how='left')\r\n",
        "\r\n",
        "#add new column to validation_truth_data witht he path to corresponding image\r\n",
        "path_to_test_images_array = []\r\n",
        "for x in testing_truth_data.values:\r\n",
        "  path_to_image = path_validation_images + str(x[0])+'.jpg'\r\n",
        "  path_to_test_images_array.append(path_to_image)\r\n",
        "#add path to image to the testing data frame\r\n",
        "validation_truth_data['path_to_image'] = path_to_test_images_array\r\n",
        "#merge testing truth data with metadata, join on the image_id's\r\n",
        "testing_data = pd.merge(validation_truth_data, validation_metadata, left_on='image_id', right_on='image_id', how='left')\r\n",
        "'''\r\n",
        "\r\n",
        "\r\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\r\n",
        "pd.set_option('display.max_colwidth', None)\r\n",
        "print(training_data.head())\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       image_id  melanoma  seborrheic_keratosis  \\\n",
            "0  ISIC_0000000       0.0                   0.0   \n",
            "1  ISIC_0000001       0.0                   0.0   \n",
            "2  ISIC_0000002       1.0                   0.0   \n",
            "3  ISIC_0000003       0.0                   0.0   \n",
            "4  ISIC_0000004       1.0                   0.0   \n",
            "\n",
            "                                                                                                 path_to_image  \\\n",
            "0  /content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC_0000000.jpg   \n",
            "1  /content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC_0000001.jpg   \n",
            "2  /content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC_0000002.jpg   \n",
            "3  /content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC_0000003.jpg   \n",
            "4  /content/drive/MyDrive/isic-challenge-2017/ISIC-2017_Training_Data/ISIC-2017_Training_Data/ISIC_0000004.jpg   \n",
            "\n",
            "  age_approximate     sex  \n",
            "0              55  female  \n",
            "1              30  female  \n",
            "2              60  female  \n",
            "3              30    male  \n",
            "4              80    male  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N43vu-BE2uHk"
      },
      "source": [
        "Image/Label Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI5EoGNEpTA0"
      },
      "source": [
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "from numpy import asarray\r\n",
        "# load the image\r\n",
        "def get_data(data, type_data):\r\n",
        "  print(f'preparing {type_data}')\r\n",
        "  print('Loading images to memory')\r\n",
        "  #load Image data, resize to 256 by 256 pixel and load into numpy array\r\n",
        "  image_data = np.array([np.array(Image.open(x[3]).resize((256,256))) for x in data.values])\r\n",
        "  print('Images Loaded')\r\n",
        "  print('Loading Labels')\r\n",
        "  #load labels into numpy array\r\n",
        "  image_label = np.array([np.array(x[1]) for x in data.values])\r\n",
        "  print('Loading Labels Finished')\r\n",
        "  return image_data, image_label\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kZrsqlw3Uxu"
      },
      "source": [
        "Generate Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_QKoihOlU21",
        "outputId": "a92cdfbb-58bc-47df-f27a-68a32b08f1e5"
      },
      "source": [
        "import numpy as np\r\n",
        "import keras\r\n",
        "# Model / data parameters\r\n",
        "num_classes = 2\r\n",
        "input_shape = (256, 256, 3)\r\n",
        "\r\n",
        "# get training data\r\n",
        "x_train, y_train = get_data(training_data,'Training Data')\r\n",
        "\r\n",
        "# Scale images to the [-1, 1] range\r\n",
        "x_train = x_train.astype(\"float32\") / 127.5 - 1\r\n",
        "\r\n",
        "print(x_train.shape[0], \"train samples\")\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing Training Data\n",
            "Loading images to memory\n",
            "Images Loaded\n",
            "Loading Labels\n",
            "Loading Labels\n",
            "2000 train samples\n",
            "(2000, 256, 256, 3)\n",
            "(2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPmSFJTd3a68"
      },
      "source": [
        "Define CNN architecture\r\n",
        "\r\n",
        "```\r\n",
        "First Iteration One Convolutional Layer\r\n",
        "  model = keras.Sequential(\r\n",
        "      [\r\n",
        "          keras.Input(shape=input_shape),\r\n",
        "          layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "          layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "          layers.Flatten(),\r\n",
        "          layers.Dropout(0.5),\r\n",
        "          layers.Dense(2, activation='sigmoid')\r\n",
        "      ]\r\n",
        "  )\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LY3PUKrl1eD",
        "outputId": "828c2b10-26f4-43f0-b9a3-95a0f1c9644c"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import layers\r\n",
        "input_shape = (256, 256, 3)\r\n",
        "#Define CNN architecture\r\n",
        "model = keras.Sequential(\r\n",
        "    [\r\n",
        "        keras.Input(shape=input_shape),\r\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "        layers.Flatten(),\r\n",
        "        layers.Dropout(0.5),\r\n",
        "        layers.Dense(2, activation='sigmoid')\r\n",
        "    ]\r\n",
        ")\r\n",
        "layers\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 516128)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 516128)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1032258   \n",
            "=================================================================\n",
            "Total params: 1,033,154\n",
            "Trainable params: 1,033,154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF2bEa5Q3-U9"
      },
      "source": [
        "Train The Model\r\n",
        "\r\n",
        "```\r\n",
        "First iteration\r\n",
        "    batch_size = 128\r\n",
        "    epochs = 10\r\n",
        "    Results:\r\n",
        "    Epoch 1/10\r\n",
        "    15/15 [==============================] - 72s 5s/step - loss: 2.9174 - accuracy: 0.7328 - val_loss: 1.0437 - val_accuracy: 0.7800\r\n",
        "    Epoch 2/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.7646 - accuracy: 0.7069 - val_loss: 1.1535 - val_accuracy: 0.5700\r\n",
        "    Epoch 3/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.5507 - accuracy: 0.7767 - val_loss: 0.7230 - val_accuracy: 0.8100\r\n",
        "    Epoch 4/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.4865 - accuracy: 0.8151 - val_loss: 0.6484 - val_accuracy: 0.7400\r\n",
        "    Epoch 5/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.3791 - accuracy: 0.8384 - val_loss: 0.6094 - val_accuracy: 0.7800\r\n",
        "    Epoch 6/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.3599 - accuracy: 0.8337 - val_loss: 0.6483 - val_accuracy: 0.7000\r\n",
        "    Epoch 7/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.3413 - accuracy: 0.8769 - val_loss: 0.6049 - val_accuracy: 0.8100\r\n",
        "    Epoch 8/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.3442 - accuracy: 0.8502 - val_loss: 0.6112 - val_accuracy: 0.7900\r\n",
        "    Epoch 9/10\r\n",
        "    15/15 [==============================] - 65s 4s/step - loss: 0.3025 - accuracy: 0.8780 - val_loss: 0.8383 - val_accuracy: 0.6700\r\n",
        "    Epoch 10/10\r\n",
        "    15/15 [==============================] - 72s 5s/step - loss: 0.3030 - accuracy: 0.8769 - val_loss: 0.7285 - val_accuracy: 0.7150\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwhi3svGl7RK",
        "outputId": "596d1dcf-5328-422e-ab7c-8431e789a2dc"
      },
      "source": [
        "batch_size = 128\r\n",
        "epochs = 10\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 256, 256, 3)\n",
            "(2000, 2)\n",
            "Epoch 1/10\n",
            "15/15 [==============================] - 72s 5s/step - loss: 2.9174 - accuracy: 0.7328 - val_loss: 1.0437 - val_accuracy: 0.7800\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.7646 - accuracy: 0.7069 - val_loss: 1.1535 - val_accuracy: 0.5700\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.5507 - accuracy: 0.7767 - val_loss: 0.7230 - val_accuracy: 0.8100\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.4865 - accuracy: 0.8151 - val_loss: 0.6484 - val_accuracy: 0.7400\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.3791 - accuracy: 0.8384 - val_loss: 0.6094 - val_accuracy: 0.7800\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.3599 - accuracy: 0.8337 - val_loss: 0.6483 - val_accuracy: 0.7000\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.3413 - accuracy: 0.8769 - val_loss: 0.6049 - val_accuracy: 0.8100\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.3442 - accuracy: 0.8502 - val_loss: 0.6112 - val_accuracy: 0.7900\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 65s 4s/step - loss: 0.3025 - accuracy: 0.8780 - val_loss: 0.8383 - val_accuracy: 0.6700\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 72s 5s/step - loss: 0.3030 - accuracy: 0.8769 - val_loss: 0.7285 - val_accuracy: 0.7150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5f11c5198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YR3a22L4jkU"
      },
      "source": [
        "Evaluate The Model Performance\r\n",
        "\r\n",
        "```\r\n",
        "First Iteration\r\n",
        "  Test loss: 0.6319829821586609\r\n",
        "  Test accuracy: 0.753333330154419\r\n",
        "```\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwNsyrSpmCAK",
        "outputId": "a14a4fb5-a81d-49d5-8735-fbaea9b215cb"
      },
      "source": [
        "x_validate, y_validate =get_data(validation_data, 'Testing Data')\r\n",
        "x_validate = x_validate.astype(\"float32\") / 127.5 - 1\r\n",
        "y_validate = keras.utils.to_categorical(y_validate, num_classes)\r\n",
        "\r\n",
        "score = model.evaluate(x_validate, y_validate, verbose=0)\r\n",
        "print(\"Test loss:\", score[0])\r\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preparing Testing Data\n",
            "Loading images to memory\n",
            "Images Loaded\n",
            "Loading Labels\n",
            "Loading Labels\n",
            "Test loss: 0.6319829821586609\n",
            "Test accuracy: 0.753333330154419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-kB9lS54rwr"
      },
      "source": [
        "Prediction and Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6wi7pnh2q4t",
        "outputId": "6d9352c9-b014-4677-9494-f745f3daa854"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "for x in testing_data.head(5).values:\r\n",
        "  img = keras.preprocessing.image.load_img(\r\n",
        "      x[3], target_size=(256,256)\r\n",
        "  )\r\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\r\n",
        "  img_array = img_array.astype(\"float32\") / 127.5 - 1\r\n",
        "  img_array = tf.expand_dims(img_array, 0)  # Create batch axis\r\n",
        "  predictions = model.predict(img_array)\r\n",
        "  score = predictions[0]\r\n",
        "  print(predictions)\r\n",
        "  print(\r\n",
        "      \"%s This image is %.2f percent malignant and %.2f percent benign.\"\r\n",
        "      % (x[0], 100 * (1 - score[0]), 100 * score[1])\r\n",
        "  )"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.16152298 0.87988365]]\n",
            "ISIC_0012086 This image is 83.85 percent malignant and 87.99 percent benign.\n",
            "[[0.97079605 0.03807449]]\n",
            "ISIC_0012092 This image is 2.92 percent malignant and 3.81 percent benign.\n",
            "[[0.98178226 0.02119675]]\n",
            "ISIC_0012095 This image is 1.82 percent malignant and 2.12 percent benign.\n",
            "[[0.7256267  0.28050297]]\n",
            "ISIC_0012134 This image is 27.44 percent malignant and 28.05 percent benign.\n",
            "[[0.8935182  0.12283656]]\n",
            "ISIC_0012136 This image is 10.65 percent malignant and 12.28 percent benign.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}